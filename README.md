# Narrative Consistency Checker

**IIT Kharagpur Data Science Hackathon 2026**

A comprehensive pipeline for checking the consistency of narratives against reference documents using Natural Language Inference (NLI) and semantic retrieval.

## ğŸ“‹ Overview

This system analyzes narratives to extract claims and verifies their consistency against a reference/ground truth document. It uses state-of-the-art NLP techniques including:

- **Text Chunking**: Intelligently splits documents into manageable pieces
- **Claim Extraction**: Identifies factual claims from narratives
- **Semantic Retrieval**: Finds relevant context using sentence embeddings
- **NLI Verification**: Verifies claims using Natural Language Inference

## ğŸ—ï¸ Project Structure

```
narrative-consistency-checker/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_input.csv                          # Input data file
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chunker.py                                # Text Chunking module
â”‚   â”œâ”€â”€ claim_extractor.py                        # Claim extraction module
â”‚   â”œâ”€â”€ retriever.py                              # Semantic retrieval module 
â”‚   â”œâ”€â”€ nli_checker.py                            # NLI verification module
â”‚   â”œâ”€â”€ pipeline.py                               # Main pipeline orchestration 
â”‚   â””â”€â”€ optimized_pipeline.py 
â”‚
â”œâ”€â”€ output/                                       # Output directory (auto created)
â”œâ”€â”€ cache/                     
â”‚
â”œâ”€â”€ requirements.txt                              # Python dependencies
â”œâ”€â”€ run.py                                        # Main execution script 
â”œâ”€â”€ run_optimized.py
â”œâ”€â”€ setup.sh
â”œâ”€â”€ setup.bat
â”œâ”€â”€ README.md                                     # This file
â”œâ”€â”€ OPTIMIZATION_GUIDE.md
â”œâ”€â”€ PERFORMANCE_COMPARISON.md
â””â”€â”€ QUICK_START.md
```

## Project Repository 

The full project, icluding tthe presentation slides, is available at:
[GitHub Repository](https://github.com/alok844937-design/narrative-consistency-checker)

## ğŸš€ Installation

### 1. Clone the repository or navigate to project directory

```bash
cd narrative-consistency-checker
```

### 2. Create a virtual environment (recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Download NLTK data (will auto-download on first run, but you can do it manually)

```python
import nltk
nltk.download('punkt')
```

## ğŸ“Š Input Format

The input CSV file should have at least two columns:
- **narrative**: The narrative text to check
- **reference**: The reference/ground truth document

Example `data/sample_input.csv`:

```csv
narrative,reference
"The company reported a 25% increase in revenue. The CEO announced expansion plans to Asia.","The company's Q4 results showed a 25% year-over-year revenue growth. The board approved a strategic expansion into Asian markets, scheduled for Q2 next year."
```

## ğŸ’» Usage

### Basic Usage

```bash
python run.py
```

### Advanced Usage

```bash
python run.py \
    --input data/sample_input.csv \
    --output output/results.json \
    --report output/report.txt \
    --chunk-size 512 \
    --top-k 3 \
    --detailed
```

### Command Line Arguments

- `--input`: Path to input CSV file (default: `data/sample_input.csv`)
- `--output`: Path to output JSON file (default: `output/results.json`)
- `--report`: Path to output report file (default: `output/report.txt`)
- `--chunk-size`: Size of text chunks in characters (default: 512)
- `--top-k`: Number of contexts to retrieve per claim (default: 3)
- `--detailed`: Include detailed context and NLI results in output

## ğŸ“ˆ Output

### JSON Output

The system generates a detailed JSON file with:

```json
{
  "status": "success",
  "summary": {
    "total_claims": 10,
    "supported": 7,
    "contradicted": 1,
    "partially_supported": 2,
    "insufficient_evidence": 0,
    "consistency_score": 0.8,
    "consistency_percentage": 80.0
  },
  "claim_verifications": [
    {
      "claim": "The company reported a 25% increase in revenue.",
      "verdict": "SUPPORTED",
      "max_entailment_score": 0.95,
      "max_contradiction_score": 0.02,
      "avg_entailment_score": 0.87
    }
  ]
}
```

### Text Report

A human-readable report with:
- Overall consistency metrics
- Per-claim verification results
- Confidence scores

## ğŸ”§ Module Details

### 1. Chunker (`src/chunker.py`)

Splits large documents into smaller, overlapping chunks for efficient processing.

**Features:**
- Sentence-based chunking
- Paragraph-based chunking
- Configurable overlap

### 2. Claim Extractor (`src/claim_extractor.py`)

Extracts factual claims from narrative text using linguistic patterns.

**Features:**
- Identifies assertive statements
- Filters out questions and non-claims
- Ranks claims by importance

### 3. Retriever (`src/retriever.py`)

Finds relevant context passages for each claim using semantic similarity.

**Features:**
- Uses sentence transformers for embeddings
- FAISS indexing for fast retrieval
- Batch processing support

### 4. NLI Checker (`src/nli_checker.py`)

Verifies claims against context using Natural Language Inference.

**Features:**
- Pre-trained BART-MNLI model
- Three-way classification (entailment, neutral, contradiction)
- Confidence scoring

### 5. Pipeline (`src/pipeline.py`)

Orchestrates the entire workflow from input to output.

**Features:**
- End-to-end processing
- Result aggregation
- Report generation

## ğŸ¯ How It Works

1. **Load Data**: Read narrative and reference texts from CSV
2. **Chunk Reference**: Split reference document into searchable chunks
3. **Extract Claims**: Identify claims in the narrative
4. **Retrieve Context**: Find relevant chunks for each claim
5. **Verify Claims**: Use NLI to check consistency
6. **Generate Report**: Create summary and detailed results

## ğŸ“ Customization

### Changing Models

Edit the model names in `run.py` or pass them to the pipeline:

```python
pipeline = NarrativeConsistencyPipeline(
    retriever_model='all-mpnet-base-v2',  # Different sentence transformer
    nli_model='microsoft/deberta-v3-large-mnli'  # Different NLI model
)
```

### Adjusting Thresholds

Modify thresholds in `src/nli_checker.py`:

```python
if max_entailment > 0.7:  # Adjust this threshold
    verdict = 'SUPPORTED'
```

## ğŸ› Troubleshooting

### Out of Memory

- Reduce `chunk_size`
- Process fewer claims at once
- Use CPU instead of GPU (automatic fallback)

### Slow Processing

- Reduce `top_k` retrieval
- Use smaller models
- Process in batches

### Poor Results

- Increase `chunk_size` for more context
- Increase `top_k` for more evidence
- Try different NLI models

## ğŸ“š Dependencies

- `pandas`: Data handling
- `numpy`: Numerical operations
- `transformers`: NLI models
- `sentence-transformers`: Semantic embeddings
- `torch`: Deep learning backend
- `faiss-cpu`: Fast similarity search
- `nltk`: Text processing

## ğŸ“ For Hackathon Submission

Make sure to:
1. Include sample input data in `data/sample_input.csv`
2. Test with your specific dataset format
3. Adjust column names in `run.py` if needed
4. Document any custom modifications
5. Include output examples in your submission


## ğŸ“§ Support

For hackathon-specific questions, contact the organizers.

## ğŸ† Good Luck!

Best wishes for the IIT Kharagpur Data Science Hackathon 2026!

---

**Note**: This system requires ~2-3GB of disk space for models and ~4GB RAM for processing. First run will download models automatically.